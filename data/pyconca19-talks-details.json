[
  {
    "ID": 155,
    "title": "Procedural Generation for fun and profit",
    "talk_description": "Techniques for algorithmic content creation have found uses in industries like film, music, and most notably video games. More importantly than that, they are extremely fun to play with. In this talk I will share procedural generation methods I have encountered in both hobby and professional projects, and how they can be implemented in Python. We will look at several methods with their applications in the generation of textures, 3D models, music, and outfits.",
    "length": 30,
    "speaker": "Luis E. Pérez Estrada",
    "speaker_bio": "Luis is an engineer at Zalon by Zalando in Berlin. He has been using Python for over 10 years to make games, compilers, services, scripts, and data analyses.",
    "category": "Quite Different"
  },
  {
    "ID": 44,
    "title": "Debugging Jupyter Notebooks",
    "talk_description": "Writing code in a Jupyter Notebook is an interactive process involving a lot of trial and error. As your code evolves, errors and bugs inevitably start to creep in. A debugger can help track them down. In this talk, we’ll go through some reasons why you may want to debug your notebook. Then, we’ll explore how you can debug notebooks with the ipdb debugger. Finally, we’ll see how we can use an IDE to track down those pesky bugs.  Questions such as 'How do you debug code in a Jupyter Notebook?' and 'Can I edit and run the cells until I get what I intended?' will be explored."
    ,
    "length": 30,
    "speaker": "Maria Khalusova",
    "speaker_bio": "Maria is a Developer Advocate at JetBrains where she has been working since 2006. She is passionate about all things data and Python. She has a degree in Applied Informatics, but learning never stops. She keeps on advancing her knowledge in Data Science, Machine Learning, Data Engineering, and relevant technologies. She understands the challenges faced by newcomers to the field, and wants to to help learners overcome those challenges by sharing her knowledge and practical tips. She also blogs, presents at software development and data science conferences, and runs PyData Montreal.",
    "category": "Tools, Testing, and Practices"
  },
  {
    "ID": 179,
    "title": "Using word2vec to see what CBC 'knows' about Canada",
    "talk_description": "What does a decade of news stories published on cbc.ca tell us about Canada? What words and ideas are associated with different cities and provinces? More telling, what does it say about unconscious biases in reporters and editors? Are certain words more associated with the word \"man\" than the word \"woman\"? With \"black\" versus \"white\", \"indigenous\", or \"immigrant\"? In this talk, I'll show how I trained a neural word embedding model with hundreds of thousands of news stories using the gensim library and explored the word associations through a Jupyter notebook.",
    "length": 30,
    "speaker": "Roberto Rocha",
    "speaker_bio": "Roberto is an investigative data journalist at the CBC who traded Excel for Jupyter notebooks years ago and has never looked back. His goals are to master NLP and network graphs in the service of journalism.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 195,
    "title": "Move Fast, and Break things, Deploying the Largest Python Site in the World.",
    "talk_description": "Have you ever wanted to move fast, but are too afraid to break too many things? Learn from the experience of deploying the largest python site in the world! It is deployed every every 7 minutes! This talk details the practical steps that we took to build our continuous deployment pipeline. We will highlight the technical challenges, discuss the tools, and share the cultural philosophy necessary. Plus, we'll explain how to recover when things break. The steps can be used by any development and infra team as a blueprint towards a continuous deployment system. Development and infra teams that already do some form of continuous deployment will identify with the problems and hear how we solved them. Others, will hopefully be inspired when they learn that they can start with the simple thing and progress step by step.",
    "length": 30,
    "speaker": "Alvaro Leiva",
    "speaker_bio": "I love Python, I grew up in a small town in Chile and one weekend, 20 years ago, I had the flu and could not go out. I decided to learn how to code in Python and that was the beginning of the road that would moved us all to the Northern California so that I could join the Production Engineering team at Instagram. Also like eating, drinking and cooking (in that order).",
    "category": "Web & Databases"
  },
  {
    "ID": 144,
    "title": "RAPIDS and cuDF: accelerating DataFrames on GPUs",
    "talk_description": "The Python data science stack is composed of a rich set of powerful libraries that work wonderfully well together, providing coherent, beautiful, Pythonic APIs that let the Data Scientist think less about programming and more about the data.  However, many of these libraries are largely single-threaded (e.g., Pandas, Scikit-Learn), and as data workflows grow larger, they quickly run up against this limitation. RAPIDS is a suite of open-source libraries that provide APIs nearly identical to existing popular Python libraries. By leveraging the massively parallel processing capabilities of GPUs, RAPIDS libraries can provide speedups of 50x or more over their purely-CPU counterparts. [cuDF](https://github.com/rapidsai/cudf) is a GPU DataFrame library following the Pandas API. [cuML](https://github.com/rapidsai/cuml) is a GPU Machine Learning library following the Scikit-Learn API. [cuGraph](https://github.com/rapidsai/cugraph) is a GPU Graph Analytics library with an API inspired by NetworkX. This talk will provide an overview of the RAPIDS ecosystem, with a focus on the cuDF library, its features and design. We'll show how cuDF combines the use of Numba, Cython, modern C++, CUDA, and Apache Arrow to build a highly performant DataFrame library that is also highly interoperable with other libraries in the PyData ecosystem. We'll show examples of workflows using cuDF both on a single GPU, and across multiple GPUs in conjunction with the Dask library. We'll also share some performance results, best practices, tips, and tricks.",
    "length": 30,
    "speaker": "Ashwin Srinath",
    "speaker_bio": "Ashwin Srinath is a Pythonista and Software Engineer at NVIDIA.  He is part of the RAPIDS team, developing Python libraries for GPU-accelerated data science. He is also an enthusiastic teacher of Python as part of communities such as Software Carpentry.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 201,
    "title": "Understanding autistic children using BioSensors and Python!",
    "talk_description": "[PyCon](https://us.pycon.org/2015/5k/) partnered with Autism Speaks in the year 2015 and conducted a 5K annual fun-run to raise awareness about Autism Spectrum Disorder. It’s great to see tech conferences supporting such a cause but wouldn’t it be incredible if we can leverage Python itself to understand autistic children and help them lead better lives? In this talk, we’ll cover the concepts of BioSensors, BioSignal Processing in Python and Machine Learning to find out how we can do just that. Since children suffering from ASD have difficulty in expressing and communicating, traditional methods of recognizing emotions through facial expressions or speech recognition tend to have very less accuracy. Hence, the technique of mapping emotions through physiological signals of the body using Biosignal Processing in Python is relatively new and un-explored which will be the basis of the talk. The talk aims to introduce various biosensors that can be used to capture the real-time physiological signals of the body, followed by the techniques involved in Biosignal processing using Python (Neurokit, BioSPPy) and finally conclude with explaining how Machine Learning algorithms like SVM and K-NN can help map these real-time signals to emotions.",
    "length": 30,
    "speaker": "Niharika Krishnan",
    "speaker_bio": "Niharika Krishnan is currently working as a Machine Learning Engineer in India focussing on building NLP solutions for TCS-Walmart. With a passion for AI and when not at work, she focuses on projects in the healthcare space. She believes in leveraging technology to help people lead better lives and her talk at PyCon is about one such projects, AutiGlove. She is a regular at hackathons, meetups and conferences and believes in learning, coding and sharing. She was selected as a mentor for Python (Data Science) for the 4th edition of Learn IT Girl. She has also been an invited speaker at tech meetups like Google Women Techmakers, Global Diversity CFP in India. With her love for python and a will to encourage young women into tech, she took up the initiative of a PyLadies Chapter in Chennai, India.",
    "category": "Quite Different"
  },
  {
    "ID": 209,
    "title": "Handling datetimes without losing your head",
    "talk_description": "Communicating dates and times with another person is not so simple. “See you at 6 o’clock on Monday” sounds understandable. But was it a.m. or p.m.? And was your friend in the same time zone as you when you said that? When we need to use and store dates and times on Python, we have similar and more intense issues since we can express a date and time in many ways. For example, “July 15, 2019 07:05 pm”, “2019-15-07 19:05:53 CDT”, “2019-07-15T23:05:53.256587-05:00”, and 1563231953, express the exact same date and time.  However, the types used and format look very different. In this talk we'll explore the python datetime best practices to reduce the complexity when using, formatting, and storing datetimes on a daily basis.",
    "length": 30,
    "speaker": "Valery Calderon",
    "speaker_bio": "Pythonista, Software Engineer at prescrypto.com, cloudacademy.com Writer, Telecommunications Engineer. PyLadies Mexico City Co-organizer, Python Guatemala Co-founder.",
    "category": "Language Features & Internals"
  },
  {
    "ID": 160,
    "title": "A Pythonista’s intro to Kafka: no, it’s not like Celery",
    "talk_description": "Large projects often use Kafka to provide durable real time processing over huge amounts of data. But, Kafka is nothing like Redis, SQS, or any Celery backend. We’ll look at how Kafka’s design makes it amazing at some tasks (real time durable processing) and awful at others (this isn’t a Celery backend for a reason). How to avoid having your Kafka clients sitting idle and ensure your messages are actually recorded in order and in real time! Finally, we’ll look at how a Pythonista can take advantage of Java-only tech like Kafka Streams with KSQL.",
    "length": 30,
    "speaker": "Tom Aratyn",
    "speaker_bio": "Tom Aratyn is the author of Building Django Web Applications (Packt 2018), former associate professor at Seneca College, and a software developer with a decade of Python software development experience.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 203,
    "title": "Data visualization with Altair: survey data case study",
    "talk_description": "We've all seen beautiful data visualizations on the web and elsewhere. A good visualization can make a persuasive point or give new insights. How can you create beautiful and useful visualizations without too much effort? The secret behind each visualization is a set of well-organized data. In this case, we look at data from online surveys, which is not typically well-organized, and see how we can transform it and easily visualize it using the 'Grammer of Graphics' approach. The 'Grammer of Graphics' is a way of associating different data points and different aspects of a chart. You can provide the type of chart that you want, specify which data you want on the x and y axes and how you want to group you data and you will get a reasonable chart. As you do a data analysis, it is important to understand your data. A visualization tool that can quickly generate useful charts during analysis and also generate the finished charts for production is ideal. The `altair` package excels at both these jobs. The `altair` package allows you to create web ready visualizations using this approach using Python.\nThis talk will demonstrate how `altair` can be used with survey data to get quick insights out of a survey,or any other data source. `Altair` is built upon Vega and Vega-Lite, which are JavaScript libraries. They work well with Jupyter notebooks and are useful for data exploration. The data behind the chart and the code for the chart itself is stored as JSON\nand can be included on any web page, so the visualizations are independent of Python.",
    "length": 30,
    "speaker": "Stephen Childs",
    "speaker_bio": "Stephen Childs is a Senior Institutional Analyst at York University, where he uses Python (among other tools) to analyze data to help promote data-based decision-making at the University. Stephen is a certified Software Carpentry Instructor, a Maintainer for the Python for Social Science Data Carpentry lesson and a co-organizer of PyData Toronto. Stephen holds a Master of Arts in Business Economics from Wilfrid Laurier University, and got his start by working with data as a researcher in Education policy. Stephen is a member of the board of the Canadian Institutional Research and Planning Association.",
    "category": "Tools, Testing, and Practices"
  },
  {
    "ID": 143,
    "title": "Fantastic anti-patterns and where to find them: pinpointing performance bottlenecks",
    "talk_description": "Is your code running slower than you would like? If so, how do you even begin identifying performance bottlenecks? This talk will teach you how to profile your Python program and interpret flame graphs to find the best candidates for speedups. Through a real-life case study, we'll also see common performance anti-patterns, and simple remediation techniques. The case study will be a crypto-assets trading strategy backtesting program that was way too slow, and for which the techniques covered in this talk yielded amazing results, and even lead to improvements to third-party libraries!",
    "length": 30,
    "speaker": "Samuel Dion-Girardeau",
    "speaker_bio": "Samuel is a software engineer at Delphia, with a background in Linguistics and Computer Science. Former startup founder, serial hackathon mentor and attendee, fervent autodidact, he has been developing and delivering natural language technology applications and web services for the last five years.",
    "category": "Quite Different // Tools, Testing, and Practices"
  },
  {
    "ID": 96,
    "title": "Building a CMS in Python with Django+Wagtail",
    "talk_description": "In this talk, I will give an overview and real-time coding demos of the power of Django+Wagtail for building intuitive content management systems. Wagtail is a framework built on top of Django that adds a whole new level of power to the Python platform. Whether you are familiar with Django or not, this talk is aimed at anyone looking to try out something other than the industry go-to of Wordpress while exploring the workflow. The talk includes an overview of features, common custom CMS issues that Wagtail handles gracefully, and code examples of creating page models and customizing the admin. I'll be showcasing a real world example of a solution we provided a client that had many complex requests. Through this exercise, I hope to illustrate the power through simplicity Wagtail provides.",
    "length": 30,
    "speaker": "Tyler Savery",
    "speaker_bio": "As Co-Founder and Chief Technology Officer of The Young Astronauts, a creative collective dedicated to the exploration and innovation of the multimedia universe, Tyler Savery oversees all company and technical operations— from internal communications strategies to future development opportunities and new business endeavours. In 2007, while attending Ryerson University, Tyler started his first business with Nev Todorovic. Originally setting out to create a video production company, they quickly realized the benefits of offering other digital media solutions such as web applications and interactive campaigns. They found success working with artists and record labels, creating campaigns that bridged early social media, web, and multimedia. In 2009, Tyler became a partner at a new advertising agency called Playground Inc. He brought a technology perspective to the company and paved the path to pivot the company into a full-service digital agency while growing the team from a five-person operation to twelve. The company’s focus at the time was designing and building platforms for new business startups including e-commerce and apps. In 2011, Savery and Creative Director Nev Todorovic, teamed up to launch The Young Astronauts, pushing the boundaries of the unknown through technology, creative, production, and strategic services for clients including major artists, brands and corporations. With his finger on the pulse of current trends across social, tech and media landscapes, Savery oversees a team of talented, young visionaries united to explore and respond to the world in new and different ways. As one of the founders, Savery plays a hands-on role in all aspects of The Young Astronauts success— from sourcing new business to hiring talent to managing company culture and client relations with a vision for the company’s evolution in this space. Additionally, Savery’s advanced skill set extends to coding, building games and creating apps, giving him a unique perspective and understanding of what’s possible to create online. As the creators of drakesviews.com the company garnered millions of impressions for the Grammy Award-winning, platinum-selling recording artist’s new album in Sprint 2016. This project has gone on to win multiple awards including a Canne Lion and two gold Clios. At the 2014 VMAs, The Young Astronauts were honoured with “Best Pop Video” for Ariana Grande’s hit music video, “Problem.” Additional clients include Selena Gomez, Justin Bieber, Bruno Mars, Childish Gambino, STX, Nike, Mozilla, Samsung, Universal, Disney, Sony, Viacom, UMG, Republic Records, Live Nation, Snapchat, and Pepsi, among others. Although Tyler focusses more on new business development, he keeps up to date with new technologies, frameworks, and development methodologies. He still considers himself a full stack developer, competent in Python, Javascript, C#, PHP, Swift, and HTML/CSS. He has a great understanding of big data systems and development operations which gives the projects he’s involved in a leading edge on scalability. A proud alumnus of Ryerson of Ryerson University in Toronto, Savery studied radio and television arts. As an undergraduate, Savery founded RUtv, which later became Ryerson University’s official television network. Growing up, Savery was deeply influenced by his interest in creative, video production, theatre, and computer programming, which he began honing his skills in early on. When he’s not working, Savery can be found making music, writing and exploring the great outdoors. Originally from Whitby, Canada, Savery currently resides in Toronto, Canada and travels frequently to New York, NY and Los Angeles, CA.",
    "category": "Web & Databases",
    "note_to_editors": "This bio is way longer than all others.  Not sure we need data from 12-years ago about this person and customer lists."
  },
  {
    "ID": 154,
    "title": "Modelling user journeys with Keras and neural networks",
    "talk_description": "Regardless of your business, being able to anticipate your users’ next action is a valuable advantage, whether that be a purchase, a view, or even a cancellation. Typical modelling approaches to predict users’ actions have focused on one specific action, e.g., conversion or churn. Here, we take a more holistic approach and don’t limit ourselves to one action. We model a users’ journey, so that we can not only anticipate a user’s action but also the one after that.",
    "length": 30,
    "speaker": "Jennifer Nguyen",
    "speaker_bio": "Jennifer is the Lead Data Scientist at Sun Life Financial’s Analytics Centre of Excellence, helping the company to build intelligent data solutions to better serve their clients. Her past experience in the field includes the Globe and Mail, Scribd and Slyce. She holds a Master’s in Machine Learning from University College London and a B. Math from the University of Waterloo. Jennifer is a strong proponent of gender diversity in her field and partners with the University of Waterloo to support young females pursuing careers in STEM.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 109,
    "title": "The zen of Python teams",
    "talk_description": "The Zen of Python, accessed by running `import this`, is a list of nineteen aphorisms that have guided the development of the language. It has good advice for how to organize our code, but what does it have to say about how we organize ourselves? Plenty: the Zen of Python is not only a solid set of development principles, but the other easter egg is that it’s packed with wisdom about how to build healthy teams. In this talk I draw upon my time as an engineering manager leading Python teams to tell stories of what the Zen of Python has to teach us about communication and conflict, building inclusive teams and transparent processes, and promoting psychological safety. Come ready to reflect on and feel inspired by a new interpretation of these principles, and bring what you learn back to your meetup, study group, open source project, or team.",
    "length": 30,
    "speaker": "Adrienne Lowe",
    "speaker_bio": "Adrienne leads engineers at verica.io. She is the former Director of Advancement of the Django Software Foundation, the non-profit backing Django, where she led fundraising for two years. She is also an O’Reilly contributor and technical editor of Head First Python 2nd Edition. Adrienne is based in Music City: Nashville, Tennessee.",
    "category": "Community, Social, Ethics, and Education"
  },
  {
    "ID": 199,
    "title": "Rust accelerated Pythons",
    "talk_description": "Sometimes you need to scale the performance of your Python code, or you need to hook into a C API.  Wouldn't it be nice not having to do that in C or C++? This talk walks through how to accelerate Python code using a binding written in Rust (a new safe, fast systems level programming language).",
    "length": 30,
    "speaker": "Dorian Pula",
    "speaker_bio": "Dorian Puła is a full-stack web app developer, Linux DevOps enthusiast, and tech writer. He graduated from the University of Toronto, where he studied Computer Science and Professional Communication. During the day he builds and maintains web applications, REST API services and CI/CD tooling that builds, tests and deploys those systems. At night he contributes to a number of open source Python, Rust and Javascript projects including Ansible, Flask and Rookeries. When he isn't coding, Dorian enjoys writing, kayaking and hiking in Ontario's back-country.",
    "category": "Quite Different"
  },
  {
    "ID": 146,
    "title": "Anomaly detection in the wild",
    "talk_description": "How can you use machine learning with python to detect situations that are weird, abnormal, or different? Anomaly detection may be your answer! In this talk, we’ll review some interesting anomaly detection applications across multiple domains (from healthcare to finance, to name a couple). Finally, we’ll walk through a practical example of anomaly detection, for use in an industrial setting, using deep-learning and TensorFlow 2.0.",
    "length": 30,
    "speaker": "Tim Hahn",
    "speaker_bio": "Tim is passionate about using python, combined with machine learning, to help Canadian manufacturers thrive. Currently, he is harnessing his passion and years of experience in heavy industry, while at Queen’s University, where he does research in the field of machinery health monitoring. Tim also dabbles in natural language processing, data visualization, and public speaking.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 89,
    "title": "How to build bulletproof integrations",
    "talk_description": "Integrating with third-party services can be challenging. Network connections, API endpoints, and third-party Python client packages are often unreliable or poorly documented. Debugging production problems can be difficult because reproducing the issue is timeconsuming. In this presentation, I will share expertise learned from years of from building and maintaining integrations with 60+ services, including Salesforce, Intercom, HubSpot, Zendesk, Xero, NetSuite, and others.",
    "length": 30,
    "speaker": "John P. Kennedy",
    "speaker_bio": "I’m a senior engineering manager that helps software companies build great teams and great software. I have 20 years of engineering and product management experience. I launched 2 SaaS products and managed an enterprise software product with annual revenue exceeding $100M. I hire and coach great people. I also write Python code.",
    "category": "Web & Databases"
  },
  {
    "ID": 129,
    "title": "From hot mess to information, or why you should spend more time processing your data",
    "talk_description": "Over the last few years machine learning has drawn a lot of attention from both inside and outside the data science community. The internet is flooded with articles on the latest or coolest algorithms. What these articles often don’t cover is that at the beginning of your project, you'll be spending a lot of time collecting, cleaning and otherwise pre-processing your data, no matter what type of project or model you’re working on. There’s a tendency to dismiss this first stage as mundane, but this couldn’t be further from the truth. This first, exploratory, stage of the analysis is when you'll learn most about the information that is available for solving your problem and how to harness it. In this talk, I’ll use practical examples to describe some of the statistical techniques that I've found most useful over the years.  For instance, box plots offer a simple way to detect outliers and inconsistencies. Others, like imputation, are more complex and can even leverage machine learning. These methods can be combined in multiple ways to create useful representations of data, making building a good model a whole lot easier.",
    "length": 30,
    "speaker": "Serena Peruzzo",
    "speaker_bio": "Serena is a senior data scientist at the analytics consultancy Bardess, currently based in Toronto, Canada. Before joining Bardess, she has worked both in academia as an ML researcher and in the industry as a data science consultant on the Australian, British and Canadian markets. Serena is passionate about education, community and tech for good and she splits her free time between mentoring data science students, organizing meetups and volunteering.",
    "category": "Community, Social, Ethics, and Education // Machine Learning & Data Science"
  },
  {
    "ID": 157,
    "title": "Genetic algorithms: making errors do all the work",
    "talk_description": "This talk presents a systematic approach to understand and implement Genetic Algorithms, with a hands-on experience of solving a real-world problem. The inspiration and methods behind GA will also be included with all the fundamental topics like fitness algorithms, mutation, crossover etc, with limitations and advantages of using it.",
    "length": 30,
    "speaker": "Raman Tehlan",
    "speaker_bio": "I am an undergraduate student at SRM University, doing B Tech in Computer Science. My field of interest is Mathematics, Server-Side Technologies and Genetic Algorithms. I am currently a Software engineering intern at Timeless co, previously at Udacity and Knowalrity. I have created more than 20+ projects and love contributing to other open-source projects. I am also a core member of PyData Delhi and recently co-organized PyData Delhi Conference.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 99,
    "title": "pyblitzdg: the future of physical model development has arrived",
    "talk_description": "In this talk, we introduce the [pyblitzdg](https://pypi.org/project/pyblitzdg/) module for physical model development and unveil some of the power that it puts into the hands of the scientific model developer. `pyblitzdg` is a new open-source Python 3 extension module that provides bindings to the C++ modelling library [blitzdg](https://github.com/WQCG/blitzdg) which incorporates the `blitz++` tensor arithmetic library. `Pyblitzdg` excels at carrying out fast simulations of wave dynamics in sophisticated geometries. With support for both Finite Volume (FV) and Discontinuous Galerkin (DG) numerical methodologies, a wide set of tools are made available to the model developer. Object-oriented programming is not required to use `pyblitzdg`, and simple procedural-style simulation programs can usually be written in a single ~100 line python 3 script. The syntax used relies on NumPy and would be familiar to users of wide-spread mathematical software like Matlab or GNU Octave. Worked examples that are relevant to real-world physical problems will be shown, and future application areas and potential extensions will be revealed.",
    "length": 30,
    "speaker": "Derek Steinmoeller",
    "speaker_bio": "Derek Steinmoeller is an alumnus of the University of Waterloo Applied Mathematics Ph.D. program, specializing in numerical methods in fluid dynamics. He also has 5 years of experience in the software development industry. Derek holds interests and expertise in a range of areas including: numerical methods and their implementations, algorithms, scientific computing, software build and test automation, and cloud-based web services. He is the lead developer of the mathematical modelling library blitzdg and its python module pyblitzdg.",
    "category": "Machine Learning & Data Science // Quite Different"
  },
  {
    "ID": 119,
    "title": "Building municipal web apps with Python",
    "talk_description": "Municipal departments all work together for the common good of our residents through our strategic plan, but we may not always be up to date on what other staff or departments are working on. The Planning Services department of the Municipality of Clarington has utilized in house expertise and infrastructure to build several apps that allow our department and other departments within the Municipality to view our current workload, collaborate on projects and stay organized.\n\nThree apps that have been the most successful at helping the departments work together will be demoed. The **Planning Applications Portal**, a portal that shows the ongoing planning applications at the municipality with reports and statistics. The **GIS Portal** that is used by the GIS professionals of the Municipality to stay organized, establish governance, collaborate and share with each other. Thirdly, the **Geospatial Data Inventory** which is a massive database of all the geospatial data that the Municipality manages, including visualization, data requests and metadata.\nAfter the brief demos we will walk through how to build one of these at your organization. They are all built with Python, HTML, CSS and JavaScript.",
    "length": 30,
    "speaker": "Cody Brown",
    "speaker_bio": "GIS Technologist with the Municipality of Clarington. • 10+ years working experience as a GIS Specialist with all ESRI products • 10+ years of python programming expertise • 10+ years experience building web mapping applications • Database Management • Expert custom map creation • Geospatial Data Analysis • Graphic Design • Website Creation and Management (HTML, CSS, JavaScript) • Geospatial Governance • Excellent at Sales Consultations and Presentations",
    "category": "Community, Social, Ethics, and Education // Quite Different"
  },
  {
    "ID": 215,
    "title": "Algorithmic bias in machine learning",
    "talk_description": "Machine learning algorithms are susceptible to both intentional and unintentional bias. Relying on biased algorithms to drive decisions can lead to unfair outcomes that have serious consequences affecting underrepresented groups of people. In this talk, we'll walk through examples of algorithmic bias in machine learning algorithms, explore tools (in Python) that can measure this bias, and discuss good ethics and software engineering strategies to mitigate bias in machine learning algorithms.",
    "length": 10,
    "speaker": "Jill Cates",
    "speaker_bio": "Jill is a data scientist at BioSymetrics, where she applies machine learning techniques to messy and complex biomedical datasets. She is a member of PyLadies and lives in Toronto, Canada.",
    "category": "Community, Social, Ethics, and Education // Machine Learning & Data Science"
  },
  {
    "ID": 223,
    "title": "Growing plants without soil using Python!",
    "talk_description": "When most of us think of agriculture, we don't think of it as a cutting-edge playground for AI, robotics, and data science development in Python. Over the years with the development of Data Science and AI methodologies, people have potentially been interested in applying these tools to different fields(finance, journalism, agriculture) to gain meaningful insights. I came across a method called Hydroponics which allows growing plants with water in the absence of soil. I was deeply interested and started to question the idea of attaching a few sensors to plants.  Given the data, I began to explore the automation of the plant growth process. This talk focuses on performing exploratory data analysis and using neural networks with Python for implementing a smart and intelligent hydroponics system.",
    "length": 10,
    "speaker": "Manav Mehra",
    "speaker_bio": "",
    "category": "Quite Different"
  },
  {
    "ID": 95,
    "title": "Coding with an accent",
    "talk_description": "There was a time that, no matter what language I was writing in, it always came out looking a little bit like FORTRAN. As I added on some OOP-ness and more modern languages, I eventually arrived at Python, a language which has a clear \"idiomatic\" style, and its own adjective. \n\nAs it happens, I learned Python and Italian at the same time. \n\nI came to Python already working with Ruby, and I came to Italian already speaking French. These languages that are superficially similar have led me to some strange accidents, like asking at the Vatican if the bathrooms were stopped, and never, ever being able to write a for-each loop without looking up the syntax.\n\nWhat I realized is that it is hard to learn to speak like a native (or really at all) when you have nobody to talk to. People care about PEP8... but a computer will keep merrily running along and not tell you that your code looks weird. Also, no matter how many times I say the same sentence to Duolingo, it's just not the same as finding myself making a mistake in the middle of, \"I went to Rome last year,\" in my first conversation with an actual Italian.\n\nTouched on in this talk: \n* The challenges of learning languages (spoken or programming) from an app\n* The (possible?) benefits of letting the other languages languish while you pick up a new one\n* The importance of community (Exercism, Meetup, and the kindness of strangers)\n* The excitement of being able to talk about the weather.",
    "length": 10,
    "speaker": "Seonaid Lee",
    "speaker_bio": "Seonaid Lee is a lifelong learner who has been mucking about with computers since her father brought home a Commodore (Super!) PET from work in the early 80s. Python is the second-from-most-recent language that she has picked up, but is rapidly becoming a favourite. She mostly uses it to munge things, and occasionally model them.",
    "category": "Community, Social, Ethics, and Education"
  },
  {
    "ID": 15,
    "title": "Forecasting and observing airfare trends using Python and neural networks",
    "talk_description": "We have always been taught that the future you book a flight, the cheaper it is. What if I said it is not? You see it's a straight line and it has a minimum at some point (someday before the flight). We are going to see how historical Airfare data can help you get the best deals for you.\n\nThe talk on the whole process, from the data, to a basic neural network on the data. With advancements in deep learning in these few years, it is very easy to train a simple statistical model to predict the prices.",
    "length": 10,
    "speaker": "Anuj Menta",
    "speaker_bio": "Graduated from the prestigious Indian Institute of Technology, Kharagpur(2017) and have spent over 5 years coding in Python. Worked with all styles of python from website development using Django and Flask to scientific computing using numpy and scikit-learn to web-scraping using Selenium. It's been a wonderful journey all along and I'm now looking forward to bring as many people on board as I can to experience what I've experienced. Speaker at Pycon India'17, Pycon France'18. Invited to Pycon Italy'18, PyData Delhi'18 and Pycon India'18.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 113,
    "title": "Narrative-focused video games development with Ren'Py, an open source engine",
    "talk_description": "The game engine, Ren'Py, is an open source engine used to make countless interactive fiction games, also known as visual novels. These include commercial hits such as (visual novel name), to viral works such as (another visual novel name) (2mil+ downloads as of Jan 2018).\n\nI learned to program in Python using this engine, and have released my commercial game with it. I have also become a data scientist at (Canadian company) due to this skillset combined with my econometrics background. Talk about an ambitious crossover!\n\nAnyhow, the talk will dig into the source code of the engine, https://github.com/renpy/renpy, such as:\n\nHow it takes care of OS level stuff for game developers, memory optimization, cross platform game saves, and all that cool stuff.",
    "length": 10,
    "speaker": "Susan Shu Chang",
    "speaker_bio": "Susan Chang is a data scientist by day and game developer by night. Python for both!",
    "category": "Quite Different"
  },
  {
    "ID": 172,
    "title": "Iron Pythonista",
    "talk_description": "As a young teenager I was very much the stereotypical nerd. For the past 12 years I have been involved in sports at an elite level - now I am working to qualify for the Ironman 70.3 World Championships. In this talk I share how I use Python to manage data at all layers of my training.",
    "length": 30,
    "speaker": "Josh Weissbock",
    "speaker_bio": "Josh works in cyber operations with the Canadian Federal government by day, and sports analytics by night. They are trying to qualify for the Ironman 70.3 World Championships and use data in every step along the way.",
    "category": "Quite Different"
  },
  {
    "ID": 221,
    "title": "Voice recognition using python and deep learning",
    "talk_description": "Calculate Mel spectrograms from human voices using python and train an algorithm to compare human voices",
    "length": 10,
    "speaker": "Cesar Osorio",
    "speaker_bio": "Data Scientist - Machine Learning engineer using Python for the last 5 years in fraud detection and pattern recognition.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 378,
    "title": "Innovating in unusual places",
    "talk_description": "",
    "length": 30,
    "speaker": "Sarah Sun",
    "speaker_bio": "",
    "category": ""
  },
  {
    "ID": 87,
    "title": "Operator overloading: you're doing it wrong",
    "talk_description": "Some languages (C++, Python) support operator overloading, and their communities are quite happy to use this nifty feature for more readable and expressive code. And some languages (Java, Go) are resolutely opposed to this terrible idea, and would sooner die than let you change the meaning of + or /. Why the divide?\n\nI'll explore some of the uses and abuses of operator overloading, and suggest ways to use it appropriately.",
    "length": 30,
    "speaker": "Greg Ward",
    "speaker_bio": "I've been programming since the 1980s, using and contributing to open source since the 1990s, and involved in the Python community since 1998. In that time, I've written a lot of code and read even more. I've learned a few good tricks and figured out some practices to avoid. I love to share this hard-earned knowledge with my fellow hackers.",
    "category": "Language Features & Internals"
  },
  {
    "ID": 169,
    "title": "PySpark: avoiding common pitfalls and keeping your sanity",
    "talk_description": "For a Python developer, using PySpark can often feel foreign, like driving a race car in sandals. You see the power, yet it feels like you're fighting against the machine.\n\nThis talk is about battle stories using PySpark from development to production, and how my many errors can lead to better code on your end. In no particular order, I'll discuss about speeding up your development, avoiding \"friendly enemies\" and testing your code. You'll see how to avoid embarrassing mistakes by seeing me making them, and you'll leave a more insightful PySpark developer.",
    "length": 30,
    "speaker": "Jonathan Rioux",
    "speaker_bio": "Jonathan is the data science practice lead for EPAM Canada, a global engineering consultancy. He worked in insurance, analytics and data science for a little over a decade. He is passionate about programming languages and how they allow to map more and more complex ideas. Jonathan is the author of _Data at scale with PySpark_ (Manning, scheduled for 2020)",
    "category": "Machine Learning & Data Science // Tools, Testing, and Practices"
  },
  {
    "ID": 211,
    "title": "Making multiple inheritance not work",
    "talk_description": "# Description\n\nThis talk is a destructive examination of the workings of Python's inheritance model. We'll learn how it works by breaking it. By breaking inheritance in various ways, we will learn about the hooks that Python gives us to interact with it. These include using the metaclass to alter the class during construction, as well as using the \\_\\_init_subclass\\_\\_ and \\_\\_subclass\\_\\_ hooks.\n\nParticular examples will include:\n\n* Implementing interfaces in Python\n* Turning inheritance off in favor of explicit reuse\n* Simplifying classes by disabling a selection of features you don't wish to use\n\nWhile none of these are meant to be particularly useful implementations, they make good use cases to show the machinery.",
    "length": 30,
    "speaker": "Andy Fundinger",
    "speaker_bio": "Andy Fundinger is a senior engineer at Bloomberg, where he develops Python applications in the Data License group and supports Python developers throughout the firm through the company's Python Guild. Andy has spoken several times at PyGotham, as well as other conferences such as PyCon, PyCascades, QCon, PyCaribbean, and EuroPython. In the past, Andy has worked on private equity and credit risk applications, web services, and virtual worlds. Andy holds a Masters of Engineering from Stevens Institute of Technology. In his spare time, Andy is a maker who works on Internet of Things (IoT) projects and teaches classes at MakerBar in Hoboken, NJ.",
    "category": "Language Features & Internals"
  },
  {
    "ID": 25,
    "title": "Introduction to asynchronous programming",
    "talk_description": "Since Python 3.5 and PEP 492, we have been able to write asynchronous programs in an easy and Pythonic way without external libraries. Even so, it is still difficult to understand what asynchronous programming is all about and when we, Python developers, should consider using it.\n\nThis talk will give you a gentle introduction to the world of asynchronous programming, focusing mostly on the core concept of async programming, how it works, and what its applications are, in order to provide a good foundation to Python developers on the topic. On top of that, we will explore a small code example (mostly involving the built-in `asyncio`) and briefly exam the source code of CPython to find out how it works. This talk will also give you some brief comparison of `threading.Thread` and `ThreadPoolExecutor`.",
    "length": 10,
    "speaker": "Juti Noppornpitak",
    "speaker_bio": "Juti focuses on helping accelerating medical research at DNAstack. Juti received his BMath in Mathematics from the University of Waterloo. He has years of experience in full-stack software development, fault-resistant and scalable software design, consulting on software development projects for academic researches and contributing to open-source projects.",
    "category": "Language Features & Internals"
  },
  {
    "ID": 23,
    "title": "Feature engineering: an apprentice’s guide to the dark art” of machine learning",
    "talk_description": "Why is feature engineering considered the ‘dark art’ of machine learning? Transforming raw data into a form that your machine learning algorithm can utilize seems mysterious and downright frightening! Bring your wizard hat and join me as this machine learning apprentice shares her personal book of feature engineering incantations.",
    "length": 30,
    "speaker": "Deborah Diller Harris",
    "speaker_bio": "Deborah Diller Harris is a graduate student in Data Science at Elmhurst College (IL). Harris is a serial entrepreneur who wanted to augment her business knowledge with technology skills. A career in data science enables her to meld her business experience with a career in technology. She is also Founder of FemDataScience whose mission is to educate, encourage and elevate women in Big Data. She is the Organizer of the TampaBay PyLadies chapter, a former Assistant Organizer of Chicago PyLadies and in 2018 started Python Club at Elmhurst College. In addition, she volunteers her time to the Python Software Foundation by serving on several committees.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 225,
    "title": "Beating your friends at board games using Python and machine learning",
    "talk_description": "Do you hate losing at board games? Do you have too many friends and too few enemies? Then this talk is for you! I will demonstrate rapid prototyping of board games in Python, training simple yet powerful game AI, and extracting their strategies in a human-understandable way to ultimately defeat all your board game foes.\n\nThis talk will cover helpful newly-introduced Python features for rapid prototyping, using keras for games, and Monte Carlo Tree Search. You will see the effectiveness of these techniques on popular games such as Settlers of Catan and Machi Koro.",
    "length": 30,
    "speaker": "Daniel Kats",
    "speaker_bio": "I’m a rock climber, board game geek, and obsessive coffee drinker. I’m also a principal researcher at Symantec Research Labs. I attended the University of Toronto, interspersed with internships at Yelp and IBM. I graduated with a B.Sc., followed by an M.Sc. studying under Prof. Eyal de Lara. In my free time I read The Atlantic, go on anger-fueled morning jogs, and show up to events 5 minutes after doors close.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 88,
    "title": "Automating data pipeline using Apache Airflow",
    "talk_description": "Today, we are moving towards machine learning. Making predictions, finding out insights based on data. For the same purpose, the initial step is to have efficient processes in place which help us in collecting data from various different data sources. Using traditional ways to collect data is tedious and cumbersome. Manually running scripts to extract, transform and load data is a trade-off with time.\n\nTo make the process efficient. The data pipeline can be automated. Scripts to extract data can be auto-scheduled using crontab. However, using crontab has its own drawbacks. One major challenge comes in monitoring. This is where an open-source tool built by Airbnb engineering team - Apache airflow helps. Airflow is a platform to programmatically author, schedule and monitor workflows.",
    "length": 30,
    "speaker": "Mridu Bhatnagar",
    "speaker_bio": "Mridu Bhatnagar is a software development engineer. Tech stack she is currently working on is Python and Django. When not coding she loves to experience outdoors, be part of community meetups to share her learnings and learn from other enthusiasts.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 82,
    "title": "Energy indicators and Jupyter Notebooks at the Canada Energy Regulator",
    "talk_description": "Data on energy markets in Canada is abundant. Various datasets are produced by different levels of governments, private companies and industry associations, international organizations and academia. However, this data is not always standardized and is not centralized. Often, data is not comparable because units are not uniform (ex. imperial, metric) and temporal periods are variable (annual, monthly, daily). Formats range from csv, excel, html or PDF.\n\n Before any analytics can commence, data needs to be extensively cleaned up. The Canadian Energy Regulator (CER), in cooperation with three other federal agencies, recently launched the [Energy Indicators](https://www.neb-one.gc.ca/nrg/tl/nrgcmmdt/index-eng.html) – a series of interactive dashboards that display most recently available public information\n related to energy commodity markets in Canada (crude oil, natural gas, electricity and Canada’s energy transition). \n\nJupyter Notebooks to accompany each dashboard have also been created to provide a transparent data access methodology to allow reproducibility by others and clear the path for more advanced analytics related to Canada’s energy information.",
    "length": 30,
    "speaker": "Margaret Skwara and Janna Rodeokova",
    "speaker_bio": "Margaret Skwara is a senior natural gas markets analyst at the National Energy Board in Calgary, Alberta.",
    "category": "Machine Learning & Data Science // Quite Different"
  },
  {
    "ID": 180,
    "title": "Python is a weirdo",
    "talk_description": "We all know Javascript is notorious for having stupid \"features\", but what can we do with Python? This talk will go through surprising features, as well as some code golf to explore surprising applications of unsurprising features. Disclaimer: This probably won't help you do your job.",
    "length": 55,
    "speaker": "Carol Chen",
    "speaker_bio": "Carol Chen is a self-taught programmer who currently works as a developer at Shopify (Rails). Before that she worked for almost a year at Hatch Canada where she worked with Django and developed a Python based computer science curriculum. She has also contributed to Sugar (mostly in Python). Lover of conferences, she has been to the Wolfram Tech Conference (where she also spoke), I/O '18, and F8 '19. She's currently 17 and resides in Toronto.",
    "category": "Community, Social, Ethics, and Education // Quite Different"
  },
  {
    "ID": 153,
    "title": "Python table manners: a clean style",
    "talk_description": "Programming is not just about writing runnable codes but writing maintainable and extensible applications. Besides the general design issue, many code quality aspects need to take care, such as PEP 8, test coverage, security, etc. Manually checking them can be time-consuming and error-prone for both writers and reviewers. Thus, I'd like to introduce tools that can help us with each of these checkings.\nIn this talk, you will hear a brief introduction of the following tools.\n\n* Dependency Management\n    * [pipenv](https://pipenv.readthedocs.io/en/latest/)\n    * [poetry](https://poetry.eustace.io)\n* Style Check\n    * [pylint](https://www.pylint.org)\n    * [flake8](http://flake8.pycqa.org)\n    * [mypy](https://mypy.readthedocs.io)\n    * [black](https://github.com/psf/black)\n* Testing\n    * [pytest](https://docs.pytest.org/en/latest/)\n    * [pytest-cov](https://github.com/pytest-dev/pytest-cov)\n    * [pytest-mock](https://github.com/pytest-dev/pytest-mock)\n    * [Hypothesis](https://hypothesis.works)\n* git commit and Change Log\n    * [Commitizen](https://github.com/commitizen)\n    * [conventional changelog](https://github.com/conventional-changelog/conventional-changelog)\n* Security\n    * [bandit](https://github.com/PyCQA/bandit)\n* Continuous Integration\n    * [drone](https://github.com/drone/drone)\n\nBy leveraging these tools, we get rid of the repetitive and tedious tasks and focus on higher-level software design. In the end, I'll propose a workflow combining all these tools which can be quickly followed and adjusted to any software project.",
    "length": 30,
    "speaker": "Wei Lee",
    "speaker_bio": "Wei Lee is a software engineer at Rakuten Slice, and now also a volunteer of PyCon TW. Being a lazy engineer, he is passionate at automating everything. Mainly use Python for automating trivial stuff and backend development. Personal Website: [https://lee-w.github.io/](https://lee-w.github.io/)",
    "category": "Community, Social, Ethics, and Education // Tools, Testing, and Practices"
  },
  {
    "ID": 147,
    "title": "Data insights from linked data",
    "talk_description": "Our entire world wide web already is composed of linked data, and so it is not surprising that cultural institutions such as libraries, archives and museums - organizations which provide and curate open data - have begun to transform their metadata into linked data.  In this talk we will explain why linked data is powerful and demonstrate the process of how to extract data insights from it using the python modules RDFlib and plotly. \n\nRDFlib is a powerful library used for working with triple data and representing information. As we will learn in this talk, linked data is queried with a query language called SPARQL which is supported by the RDFlib library. We’ll move from parsing data and then bring out your inner artist with plotly to create visualizations. The plot will thicken when we briefly touch upon how machine learning can be applied to linked data and the ways in which working with linked metadata is different and has unique promises not present in other forms of linked data. \nBy the end of this talk you will be able to see for yourself how to draw relationships out of open linked data and the vale of communicating the relationships visible in linked data.",
    "length": 30,
    "speaker": "Rachel Wang and Jordan Pedersen",
    "speaker_bio": "Rachel Wang is a Software Developer and Pythonista at the University of Toronto Libraries. She regularly uses Python to support ETL and data heavy tasks at the library. When away from the keyboard she enjoys helping others learn technical skills as an instructor with the Software Carpentry community. Rachel is also a co-organizer for a meetup called Code4Lib Toronto which brings together communities from libraries, museums, archives and technology all in one room. When she isn’t using Python, Golang and Vue.js are always on her mind. You can find her @rwangca.                       Hey, I'm Jordan, metadata librarian at the University of Toronto libraries, and enthusiastic newbie to python. I am a certified Carpentries instructor, regular participant at Code4Lib Toronto, and huge proponent of the connection between tech and creativity. I also love to balance my technically-focused work life with non-technical things, like hiking, doodling, and hanging out with animals (specifically cows, chickens and llamas).",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 100,
    "title": "Pull requests: merging good practices into your project",
    "talk_description": "Although known by most, **Pull Requests are often not dealt with in the most effective way**. Believe it or not, **there are teams that don’t review code at all!** People may assume that a senior developer is experienced enough to not make any mistakes, or that merely changing those 3 lines of code couldn’t possibly do any harm to the system. In these cases, it’s not uncommon to skip the code review in order to cut some time. Unreviewed (or badly reviewed) code can be extremely dangerous, resulting in huge risks and unpredictable behavior.\n\nA survey says that, on average, **developers spend 45% of their time fixing bugs and technical debt**, when they could be developing new features instead. Defining simple guideline files, adopting certain behaviors and setting up repository configurations are steps that can increase manyfold the code review performance (in both time and quality). Using review tools both on server (e.g. Heroku Review Apps) and locally (e.g. linters) can also greatly increase the process’ speed. Creating templates and checklists ensures no step is overlooked or forgotten. The list goes on, but enough spoilers for now. The attendees will learn specific tips, tools, processes and recommended practices that were compiled from research and real-life use cases (both from my experience and from big players like Django, Facebook, Mozilla, etc), along with some survey data that demonstrates why reviewing code is important.",
    "length": 30,
    "speaker": "Luca Bezerra",
    "speaker_bio": "I have a Masters degree in Computer Science and over 7 years of professional experience (plus a few more as a hobbyist). I’ve worked with several technologies, Python/Django/React being the one(s) I spent the most time with. I’m a full stack developer (Flask/React) at Points International, based in Toronto. I also like to work on side-projects, although my last big ones took place a while ago. I got the 4th Place in the World at Microsoft's Imagine Cup in 2011, in the Game Design Category with a [puzzle-like computer game](https://www.youtube.com/watch?v=U_pq3fBnH8I) made by my team and competed again with [another game](https://www.youtube.com/watch?v=8QqGDRLUbfI) in 2012. I've also won the 1st National Place in the same competition in 2015, in the Citizenship category, where my team and I developed an app for helping with the treatment for Autism.",
    "category": "Community, Social, Ethics, and Education // Tools, Testing, and Practices"
  },
  {
    "ID": 97,
    "title": "How to level up",
    "talk_description": "Want to take your career to the next level? Aren’t sure you’re doing what it takes to grow? In this talk we’ll discuss how the attitudes of curiosity (learning for the sake of learning), bravery (following your fears), dissatisfaction (discontentment as motivation for improvement) and reflection (taking time to absorb what you’ve learned) can help you continually grow and level up.",
    "length": 30,
    "speaker": "Leta Montopoli",
    "speaker_bio": "",
    "category": "Community, Social, Ethics, and Education"
  },
  {
    "ID": 33,
    "title": "Why that great machine learning research can’t be reproduced and how to fix it",
    "talk_description": "Ever got excited about a piece of new machine learning research that you saw come out on arXiv or your favorite research lab’s blog hoping it will finally solve that last bit of optimization you need in your own work that will make you the ML superstar of your team? But after spending days trying to get the same results, you end up failing despite having tried everything in the paper including looking through their Github page, contacting the authors, etc. \n\nIf this sounds familiar, you’re not alone! Everyday researchers and practitioners alike spend countless hours trying to replicate results from new ML research coming out but inevitably lose precious time and compute resources failing to achieve the required results. We’re facing a massive reproducibility crisis in the field of machine learning. There has been a rise in the ease of use of tools to develop machine learning (ML) based solutions, e.g. AutoML (1) for those with limited ML experience, Keras (2) as a high level API to do more in depth ML work, etc. At the same time, there are a lot more public datasets (3) available, increasingly so to do socially oriented research, e.g. in bias detection, loan approvals, criminal risk score predictions, etc. With more people entering the field coming from diverse trainings (4), it is not necessary that all adhere to rigorous standards of scientific research. This is evidenced by recent calls by the technical research community at conferences like NeurIPS (5). \n\nWe see that a lack of reproducibility in ML research will be a key hindrance in meaningful use of R&D resources. There is currently a lack of a comprehensive framework for doing reproducible machine learning. \n\nWe as Pythonistas who love to write well-maintained, up-to-date, Pythonic code can do something to help this! \n\nThrough my own work in this domain and the work of the intern cohort that worked on the Reproducibility in Machine Learning project this summer at the Montreal AI Ethics Institute, let’s talk through some of the social and technical aspects of this problem and how you can take these principles from the talk today and become the superhero of your ML team elevating the quality of the work coming from your team and helping others build on top of your work - which is something that we pride ourselves in the Python community!\n\nWe’ll walk through the following principles and apply them to a case study to understand how this simple yet effective mechanism can help address a ton of the issues that we face in the field. \n\nOur framework combines existing tooling with policy applied to the following areas: \n\n1) solution design, \n\n2) data collection, \n\n3) model development, \n\n4) data and model legacy,\n\n5) deployment performance tracking \n\nEach section provides necessary and sufficient information to reproduce results and guide policy decisions and social changes that rely on such research. Each of these 5 parts comes with a checklist, suggested technical tools and metrics that aid in rigorous scientific development. \n\nReferences:\n\n1) https://cloud.google.com/automl/ \n\n2) https://keras.io \n\n3) https://www.kaggle.com/datasets, https://github.com/awesomedata/awesome-public-datasets \n\n4) https://jfgagne.ai/talent/ \n\n5) “Call for Papers” by Neural Information Processing Systems Conference https://link.medium.com/ZXHwZFkQQV",
    "length": 30,
    "speaker": "Abhishek Gupta",
    "speaker_bio": "Abhishek Gupta is the founder of Montreal AI Ethics Institute (https://montrealethics.ai ) and a Machine Learning Engineer at Microsoft where he serves on the CSE AI Ethics Review Board. His research focuses on applied technical and policy methods to address ethical, safety and inclusivity concerns in using AI in different domains. He has built the largest community driven, public consultation group on AI Ethics in the world that has made significant contributions to the Montreal Declaration for Responsible AI, the G7 AI Summit, AHRC and WEF Responsible Innovation framework and the European Commission Trustworthy AI Guidelines. His work on public competence building in AI Ethics has been recognized by governments from North America, Europe, Asia and Oceania. Short selection of conferences where I’ve presented: G7 AI Summit - Future of Work Transatlantic ICT Forum at the European Parliament - AI and Social Inclusion AI Conference by the Canadian German Chamber of Industry and Commerce - AI automation and employee replacement – What precautions can be taken to avoid sector specific unemployment? International Network for Government Science Advice - AI Expert guiding discussions from a technical and policy perspective on the impact that AI will have on wellbeing Rightscon 2018 - Workers Data Rights - Making sure the human remains in human resources World Summit AI (April 2019) - How can we ensure algorithmic fairness and avoid bias, or do the proposed solutions themselves create inherent bias? (Please see my website for links and a more comprehensive list of presentations) Links to videos of some of my talks: Interview with BorealisAI that took a dive into the threat automation poses to job loss based on the current science, whether bias is the biggest problem we face in responsible AI, and what we should consider reasonable trade-offs for improving fairness. https://www.youtube.com/watch?v=Z3Tme0WU5D8 Presentation at the Montreal AI Symposium on a framework for ethical development of AI systems https://www.youtube.com/watch?v=cdcKwefTT6M&t=9737s Presentation at the Brookfield Institute for Entrepreneurship and Innovation on ethics in AI and the moral attributes of intelligent systems https://www.youtube.com/watch?v=XTdAjFCqnSg Interview from AI for Good Global Summit 2018 https://www.youtube.com/watch?v=LH5t_osKck4 More information on my work can be found at https://atg-abhishek.github.io and https://montrealethics.ai",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 148,
    "title": "Query better with Django ORM",
    "talk_description": "Django ORM is extremely powerful and is a vital part of the framework. Being simple and intuitive to use, often some of its advanced features remain unutilized, leading to inefficiencies. In this cookbook style tutorial, a selection of nontrivial query usecases will be addressed, each of which will introduce an ORM feature or two. Notable ones covered will be advanced querying techniques, database functions, performance optimization, and legacy databases. In this interactive session, participants would be encouraged to share knowledge or ask questions based on their real-life challenges related to the topic at hand. The session will end with a discussion on ORM features recently introduced in Django as well as upcoming ones.",
    "length": 55,
    "speaker": "Mafinar Khan",
    "speaker_bio": "Mafinar Khan learned Python in 2001 and since then not a week passed without any involvement with Python, be it through coding, writing or speaking. He has been with the Python community of Bangladesh from the very beginning and participated in various workshops, seminars, and conferences. Professionally working with Python since 2009, Mafinar constructed several Asset Tracking Solutions, business automation systems and productivity tools with it. He is currently working at [Planswell](http://planswell.com). When not coding, Mafinar enjoys movies, really spicy foods, and annoying his 5 year old.",
    "category": "Tools, Testing, and Practices // Web & Databases"
  },
  {
    "ID": 122,
    "title": "Do-it-yourself Natural Language Processing for makers",
    "talk_description": "Susan Li walks you through deep learning methods for natural language processing (NLP) tasks using Python and open source libraries, using a live example. Methods include word2vec embedding, recurrent neural networks (RNN) and convolutional neural networks (CNN). \n\nThis is a hands-on approach to framing a real-world problem to the underlying NLP tasks and building a NLP application using Deep Learning.\n\nIf you are a data scientist or software developer with experience in Python who wants to develop natural language processing software, this talk is for you.",
    "length": 55,
    "speaker": "Susan Li",
    "speaker_bio": "I am Susan Li, the Sr. Data Scientist at Kognitiv where I specialize in machine learning and NLP. I’m passionate about helping organizations realize the potential of big data and advanced analytics, and helping individuals enhance skills in data literacy. I frequently write and speak about predictive analytics, machine learning and NLP for technical and general audience. In my free time, I can be found training for the next half marathon.",
    "category": "Machine Learning & Data Science"
  },
  {
    "ID": 114,
    "title": "A need for speed: accelerating your math with vectorization and Numpy",
    "talk_description": "While Python is an extremely versatile language, it isn't exactly known for its blazing performance. When developing math-intensive applications, particularly on low-power devices such as single-board computers, this can become a real issue. This talk provides an introduction to vectorization and libraries designed to support it (such as Numpy), giving you the tools you need to eliminate those pesky for loops and achieve a drastic performance boost.",
    "length": 55,
    "speaker": "Kyle Kotowick, Ph.D.",
    "speaker_bio": "Dr. Kotowick is the founder of a Canadian consulting and development firm focusing on prototype and POC development for complex systems. He holds a Ph.D. in Human Systems Integration from MIT's Department of Aeronautics and Astronautics, which he completed in the Computer Science and Artificial Intelligence Laboratory. He has served as a consultant, architect, and developer for global firms, startups, and universities; as the Director of Information Technology for an ambulance service; and as a researcher for military navigation systems and for life support systems in space. He specializes in working with enterprise clients to define requirements and explore possible solutions, as well as in leading the development of project architecture, cloud services, and back-end software. He volunteers as a team leader and technology specialist for World Health Organization Emergency Medical Teams deployed to disaster zones, and has a passion for exploring the uses of technology in high-risk environments.",
    "category": "Machine Learning & Data Science"
  }
]
